{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import tensorflow as tf\n",
    " \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "models =  tf.keras.models\n",
    "layers = tf.keras.layers \n",
    "scikit_learn = tf.keras.wrappers.scikit_learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequential = models.Sequential\n",
    "Dense = layers.Dense\n",
    "KerasClassifier = scikit_learn.KerasClassifier\n",
    "to_categorical = tf.keras.utils.to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data():\n",
    "    dataframe = pandas.read_csv(\"iris.csv\", header=None)\n",
    "    dataset = dataframe.values\n",
    "    # split into input (X) and output (Y) variables\n",
    "    X = dataset[:,0:4].astype(float)\n",
    "    Y = dataset[:,4]\n",
    "    le = LabelEncoder()\n",
    "    le.fit(Y)\n",
    "    encoded_Y = le.transform(Y)\n",
    "    #X_train, X_test, Y_train, Y_test = train_test_split(X, encoded_Y, test_size=.05)\n",
    "    \n",
    "    #return (X_train, Y_train, X_test, Y_test)\n",
    "    return (X, to_categorical(encoded_Y), [], [])\n",
    "    #return (X, encoded_Y, [], [])\n",
    "\n",
    "(X_train, Y_train, X_test, Y_test) = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(8, activation='relu', input_shape=(4, )))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_estimator(epochs=100):\n",
    "# evaluate model with standardized dataset\n",
    "    numpy.random.seed(seed)\n",
    "    estimator = KerasClassifier(build_fn=create_baseline, epochs=epochs, batch_size=5, verbose=0)\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    #predicted = cross_val_predict(pipeline, X_test, Y_test, cv=10)\n",
    "    #print(\"Test Accuracy: %.2f%%\" % (metrics.accuracy_score(Y_test, predicted)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_normalize(epochs=100): \n",
    "    estimators = []\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=epochs, batch_size=5, verbose=0)))\n",
    "    pipeline = Pipeline(estimators)\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    results = cross_val_score(pipeline, X_train, Y_train, cv=kfold)\n",
    "    print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    #predicted = cross_val_predict(pipeline, X_test, Y_test, cv=10)\n",
    "    #print(\"Test Accuracy: %.2f%%\" % (metrics.accuracy_score(Y_test, predicted)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 96.67% (5.37%)\n"
     ]
    }
   ],
   "source": [
    "#(X_train, Y_train, X_test, Y_test) = load_data()\n",
    "do_estimator(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 94.67% (5.81%)\n"
     ]
    }
   ],
   "source": [
    "#(X_train, Y_train, X_test, Y_test) = load_data()\n",
    "do_normalize(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_smaller():\n",
    "    model = Sequential()    \n",
    "    model.add(layers.Dense(4, activation='relu', input_shape=(4, )))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_normalize_smaller(epochs=100):\n",
    "    numpy.random.seed(seed)\n",
    "    estimators = []\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=epochs, batch_size=5, verbose=0)))\n",
    "    pipeline = Pipeline(estimators)\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    results = cross_val_score(pipeline, X_train, Y_train, cv=kfold)\n",
    "    print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    #predicted = cross_val_predict(pipeline, X_test, Y_test, cv=10)\n",
    "    #print(\"Test Accuracy: %.2f%%\" % (metrics.accuracy_score(Y_test, predicted)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 95.33% (5.21%)\n"
     ]
    }
   ],
   "source": [
    "#(X_train, Y_train, X_test, Y_test) = load_data()\n",
    "do_normalize_smaller(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_larger():\n",
    "    model = Sequential()    \n",
    "    model.add(layers.Dense(8, activation='relu', input_shape=(4, )))\n",
    "    #model.add(layers.Dropout(.2))\n",
    "    model.add(layers.Dense(4, activation='relu'))\n",
    "    #model.add(layers.Dropout(.2))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_normalize_larger(epochs=100):\n",
    "    numpy.random.seed(seed)\n",
    "    estimators = []\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=epochs, batch_size=5, verbose=0)))\n",
    "    pipeline = Pipeline(estimators)\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    results = cross_val_score(pipeline, X_train, Y_train, cv=kfold)\n",
    "    print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    #predicted = cross_val_predict(pipeline, X_test, Y_test, cv=10)\n",
    "    #print(\"Test Accuracy: %.2f%%\" % (metrics.accuracy_score(Y_test, predicted)*100))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 94.00% (7.57%)\n"
     ]
    }
   ],
   "source": [
    "#(X_train, Y_train, X_test, Y_test) = load_data()\n",
    "do_normalize_larger(epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizers = tf.keras.regularizers\n",
    "\n",
    "def create_scale_up():\n",
    "    model = Sequential()    \n",
    "    model.add(layers.Dense(8, activation='relu', input_shape=(4, )))\n",
    "    #model.add(layers.Dropout(.2))\n",
    "    model.add(layers.Dense(8, activation='relu'))\n",
    "    model.add(layers.Dense(4, activation='relu'))\n",
    "    \n",
    "    #model.add(layers.Dropout(.2))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_normalize_scale_up(epochs=100):\n",
    "    numpy.random.seed(seed)\n",
    "    estimators = []\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    model = KerasClassifier(build_fn=create_scale_up, epochs=epochs, batch_size=5, verbose=0)\n",
    "    estimators.append(('mlp', model))\n",
    "    pipeline = Pipeline(estimators)\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    results = cross_val_score(pipeline, X_train, Y_train, cv=kfold)\n",
    "    print(\"Scale Up: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    #predicted = cross_val_predict(pipeline, X_test, Y_test, cv=10)\n",
    "    #print(\"Test Accuracy: %.2f%%\" % (metrics.accuracy_score(Y_test, predicted)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale Up: 96.67% (4.47%)\n"
     ]
    }
   ],
   "source": [
    "#(X_train, Y_train, X_test, Y_test) = load_data()\n",
    "do_normalize_scale_up(epochs = 200)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_functional():\n",
    "    inputs = tf.keras.Input(shape=(4, ))\n",
    "    x = layers.Dense(8, activation=\"relu\")(inputs)\n",
    "    x = layers.Dense(8, activation=\"relu\")(x)\n",
    "    x = layers.Dense(4, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_normalize_functional(epochs=100):\n",
    "    numpy.random.seed(seed)\n",
    "    estimators = []\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    model = KerasClassifier(build_fn=create_functional, epochs=epochs, batch_size=5, verbose=0)\n",
    "    estimators.append(('mlp', model))\n",
    "    pipeline = Pipeline(estimators)\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    results = cross_val_score(pipeline, X_train, Y_train, cv=kfold)\n",
    "    print(\"Functional: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    #predicted = cross_val_predict(pipeline, X_test, Y_test, cv=10)\n",
    "    #print(\"Test Accuracy: %.2f%%\" % (metrics.accuracy_score(Y_test, predicted)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_normalize_functional(epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = layers.Dense(8, activation=\"relu\")\n",
    "        self.dense2 = layers.Dense(8, activation=\"relu\")\n",
    "        self.dense3 = layers.Dense(4, activation=\"relu\")\n",
    "        self.dense4 = layers.Dense(3, activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return self.dense4(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_subclass():\n",
    "    model = MyModel()\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_normalize_mymodel(epochs=100):\n",
    "    \n",
    "    #my_model = MyModel()\n",
    "    numpy.random.seed(seed)\n",
    "    estimators = []\n",
    "    estimators.append(('standardize', StandardScaler()))\n",
    "    model = KerasClassifier(build_fn=create_model_subclass, epochs=epochs, batch_size=5, verbose=0)\n",
    "    estimators.append(('mlp', model))\n",
    "    pipeline = Pipeline(estimators)\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    results = cross_val_score(pipeline, X_train, Y_train, cv=kfold)\n",
    "    print(\"MyModel: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    #predicted = cross_val_predict(pipeline, X_test, Y_test, cv=10)\n",
    "    #print(\"Test Accuracy: %.2f%%\" % (metrics.accuracy_score(Y_test, predicted)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_normalize_mymodel(epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyKFold(X, Y, mymodel, n_splits=10, epochs=100):\n",
    "    validation_sample = len(X) // n_splits\n",
    "    validation_scores = []\n",
    "    numpy.random.shuffle(X)\n",
    "    numpy.random.shuffle(Y)\n",
    "    val_acc =[]\n",
    "    acc = []\n",
    "    for fold in range(n_splits):\n",
    "        validation_X = X[validation_sample*fold:validation_sample*(fold+1)]\n",
    "        training_X = numpy.concatenate((X[:validation_sample*fold] , X[validation_sample*(fold+1):]), axis=0)\n",
    "        validation_Y = Y[validation_sample*fold:validation_sample*(fold+1)].astype(float)\n",
    "        training_Y = numpy.concatenate((Y[:validation_sample*fold] , Y[validation_sample*(fold+1):]), axis=0).astype(float)\n",
    "        model = mymodel\n",
    "        history= model.fit(training_X, training_Y, epochs=epochs,batch_size=5, validation_data=(validation_X, validation_Y), verbose=0)\n",
    "        validation_scores.append(history)\n",
    "        val_acc.append(history.history['val_acc'])\n",
    "        acc.append(history.history['acc'])\n",
    "\n",
    "    print(\"MyKFold (Validation): %.2f%% (%.2f%%)\" % (numpy.mean(val_acc)*100, numpy.std(val_acc)*100))\n",
    "    print(\"MyKFold (Training): %.2f%% (%.2f%%)\" % (numpy.mean(acc)*100, numpy.std(acc)*100))\n",
    "\n",
    "    return history\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = MyKFold(X_train, Y_train, create_scale_up(), n_splits=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "acc = history_dict['acc']\n",
    "loss_value = history_dict['loss']\n",
    "val_loss_value = history_dict['val_loss']\n",
    "val_acc = history_dict['val_acc']\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss_value, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss_value, 'b', label='Validation Loss')\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\") \n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
