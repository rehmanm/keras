{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import copy_data as cp\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = tf.keras.layers\n",
    "models = tf.keras.models\n",
    "optimizers = tf.keras.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/notebooks/cats_and_dogs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Copy files</b> <br />\n",
    "Copy all the files in the folder and return the base_dir for processsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = cp.CopyImages(path, 1000, 500, 500)\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "validation_dir = os.path.join(base_dir, \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(150, 150, 3)))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\", \n",
    "        optimizer=optimizers.RMSprop(lr = 1e-4),\n",
    "        metrics= ['acc']\n",
    "        )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding <b>Generators</b> for processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "     train_dir, \n",
    "     target_size=(150, 150),\n",
    "     batch_size=20,\n",
    "     class_mode='binary'\n",
    ")\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "     validation_dir, \n",
    "     target_size=(150, 150),\n",
    "     batch_size=20,\n",
    "     class_mode='binary'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fitting Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.6847 - acc: 0.5345 - val_loss: 0.6576 - val_acc: 0.6220\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.6481 - acc: 0.6300 - val_loss: 0.7095 - val_acc: 0.5520\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.5995 - acc: 0.6825 - val_loss: 0.6126 - val_acc: 0.6610\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.5538 - acc: 0.7075 - val_loss: 0.5936 - val_acc: 0.6720\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.5204 - acc: 0.7470 - val_loss: 0.6168 - val_acc: 0.6770\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.4938 - acc: 0.7585 - val_loss: 0.5740 - val_acc: 0.7060\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.4681 - acc: 0.7750 - val_loss: 0.5865 - val_acc: 0.6810\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.4342 - acc: 0.8015 - val_loss: 0.5670 - val_acc: 0.7060\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.4152 - acc: 0.8105 - val_loss: 0.5508 - val_acc: 0.7310\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.3826 - acc: 0.8255 - val_loss: 0.5866 - val_acc: 0.7180\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.3569 - acc: 0.8405 - val_loss: 0.6031 - val_acc: 0.7150\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.3338 - acc: 0.8590 - val_loss: 0.5672 - val_acc: 0.7410\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.3030 - acc: 0.8765 - val_loss: 0.6608 - val_acc: 0.7000\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.2814 - acc: 0.8845 - val_loss: 0.7210 - val_acc: 0.6990\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.2524 - acc: 0.8990 - val_loss: 0.6503 - val_acc: 0.7090\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.2320 - acc: 0.9080 - val_loss: 0.6040 - val_acc: 0.7430\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.2063 - acc: 0.9290 - val_loss: 0.6474 - val_acc: 0.7310\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.1940 - acc: 0.9275 - val_loss: 0.6602 - val_acc: 0.7260\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.1652 - acc: 0.9425 - val_loss: 0.7229 - val_acc: 0.7240\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.1423 - acc: 0.9505 - val_loss: 0.6885 - val_acc: 0.7370\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.1214 - acc: 0.9610 - val_loss: 0.7935 - val_acc: 0.7290\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.1113 - acc: 0.9665 - val_loss: 0.8452 - val_acc: 0.7150\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0962 - acc: 0.9695 - val_loss: 0.7951 - val_acc: 0.7320\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0815 - acc: 0.9785 - val_loss: 1.2330 - val_acc: 0.6730\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0733 - acc: 0.9730 - val_loss: 0.9561 - val_acc: 0.7150\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0586 - acc: 0.9885 - val_loss: 0.9302 - val_acc: 0.7310\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0540 - acc: 0.9845 - val_loss: 0.9815 - val_acc: 0.7200\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 103s 1s/step - loss: 0.0397 - acc: 0.9905 - val_loss: 1.0259 - val_acc: 0.7180\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.0403 - acc: 0.9890 - val_loss: 1.2725 - val_acc: 0.7170\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 104s 1s/step - loss: 0.0293 - acc: 0.9910 - val_loss: 1.1462 - val_acc: 0.7290\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cat_and_dogs_small1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
